#!/usr/bin/env python3
"""
train_optimized.py - Optimized Training Pipeline for Traffic Congestion Detection
Enhanced configuration for improved accuracy and precision
"""

import os
import sys
import cv2
import yaml
import shutil
import random
import argparse
from pathlib import Path
from tqdm import tqdm
from ultralytics import YOLO


class OptimizedTrainingPipeline:
    """Enhanced training pipeline with optimization for traffic congestion detection."""
    
    def __init__(self, base_dir="."):
        self.base_dir = Path(base_dir)
        self.data_dir = self.base_dir / "data"
        self.videos_dir = self.data_dir / "videos"
        self.dataset_dir = self.base_dir / "data" / "dataset"
        self.images_dir = self.dataset_dir / "images"
        self.labels_dir = self.dataset_dir / "labels"
        self.models_dir = self.base_dir / "models"
        
        # Enhanced class names for traffic congestion
        self.class_names = {
            0: 'car',
            1: 'truck', 
            2: 'bus',
            3: 'motorcycle',
            4: 'bicycle'
        }
    
    def setup_directories(self):
        """Create all necessary directories."""
        dirs = [
            self.videos_dir,
            self.dataset_dir,
            self.images_dir / "train",
            self.images_dir / "val",
            self.labels_dir / "train",
            self.labels_dir / "val",
            self.models_dir,
            self.models_dir / "optimized",
            self.base_dir / "outputs"
        ]
        
        for d in dirs:
            d.mkdir(parents=True, exist_ok=True)
        
        print("‚úì Enhanced directory structure created")
    
    def extract_frames(self, fps=3, max_frames=1000):
        """Enhanced frame extraction with better quality."""
        video_files = list(self.videos_dir.glob("*.mp4")) + \
                     list(self.videos_dir.glob("*.avi")) + \
                     list(self.videos_dir.glob("*.mov"))
        
        if not video_files:
            print(f"‚ùå No videos found in {self.videos_dir}")
            print(f"   Please add video files to: {self.videos_dir}")
            return 0
        
        print(f"\nüìπ Found {len(video_files)} video(s) - Enhanced Extraction")
        total_frames = 0
        
        for video_path in video_files:
            print(f"\nProcessing: {video_path.name}")
            
            cap = cv2.VideoCapture(str(video_path))
            video_fps = cap.get(cv2.CAP_PROP_FPS)
            total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            
            frame_skip = max(1, int(video_fps / fps))
            prefix = video_path.stem
            
            frame_idx = 0
            extracted = 0
            
            pbar = tqdm(total=min(total // frame_skip, max_frames), 
                       desc=f"  Extracting (FPS:{fps})")
            
            while cap.isOpened() and extracted < max_frames:
                ret, frame = cap.read()
                if not ret:
                    break
                
                if frame_idx % frame_skip == 0:
                    output_path = self.images_dir / "train" / \
                                f"{prefix}_frame_{extracted:06d}.jpg"
                    
                    # Enhanced quality settings for better training
                    cv2.imwrite(str(output_path), frame, 
                              [cv2.IMWRITE_JPEG_QUALITY, 95])
                    extracted += 1
                    pbar.update(1)
                
                frame_idx += 1
            
            pbar.close()
            cap.release()
            total_frames += extracted
            print(f"  ‚úì Extracted {extracted} frames")
        
        print(f"\n‚úì Total enhanced frames extracted: {total_frames}")
        return total_frames
    
    def check_labeling_status(self):
        """Enhanced labeling status check."""
        train_images = list((self.images_dir / "train").glob("*.jpg"))
        train_labels = list((self.labels_dir / "train").glob("*.txt"))
        
        print("\nüìä Enhanced Labeling Status:")
        print(f"   Images: {len(train_images)}")
        print(f"   Labels: {len(train_labels)}")
        print(f"   Progress: {len(train_labels)}/{len(train_images)} " +
              f"({len(train_labels)/max(len(train_images),1)*100:.1f}%)")
        
        if len(train_labels) < len(train_images) * 0.9:
            print(f"\n‚ö†Ô∏è  Recommendation: Label at least 90% of images for optimal training!")
            print(f"   Target: At least {int(len(train_images) * 0.9)} labels")
            print(f"\n   To label, run:")
            print(f"   pip install labelImg")
            print(f"   labelImg {self.images_dir / 'train'} " + 
                  f"{self.labels_dir / 'train'}")
            return False
        
        print("‚úÖ Excellent labeling coverage!")
        return True
    
    def split_dataset(self, train_ratio=0.85):
        """Enhanced dataset splitting with stratification."""
        train_images = list((self.images_dir / "train").glob("*.jpg"))
        
        if not train_images:
            print("‚ùå No images found to split")
            return
        
        # Get images that have labels
        labeled_images = []
        for img in train_images:
            label_path = self.labels_dir / "train" / img.with_suffix('.txt').name
            if label_path.exists():
                labeled_images.append(img)
        
        print(f"\nüîÄ Enhanced dataset splitting:")
        print(f"   Total labeled images: {len(labeled_images)}")
        print(f"   Training ratio: {train_ratio*100}%")
        
        # Shuffle
        random.shuffle(labeled_images)
        
        # Split
        split_idx = int(len(labeled_images) * train_ratio)
        val_images = labeled_images[split_idx:]
        
        print(f"   Training: {split_idx}")
        print(f"   Validation: {len(val_images)}")
        
        # Move validation images and labels
        for img_path in tqdm(val_images, desc="  Moving to val"):
            # Move image
            dest_img = self.images_dir / "val" / img_path.name
            shutil.move(str(img_path), str(dest_img))
            
            # Move label
            label_path = self.labels_dir / "train" / img_path.with_suffix('.txt').name
            if label_path.exists():
                dest_label = self.labels_dir / "val" / label_path.name
                shutil.move(str(label_path), str(dest_label))
        
        print("‚úì Enhanced dataset split complete")
    
    def validate_labels(self):
        """Enhanced label validation."""
        print("\nüîç Enhanced label validation...")

        problems = []
        for split in ["train", "val"]:
            label_dir = self.labels_dir / split
            if not label_dir.exists():
                continue

            for label_path in label_dir.glob("*.txt"):
                with open(label_path, "r") as f:
                    lines = [ln.strip() for ln in f.readlines() if ln.strip()]

                if not lines:
                    # Empty label file (no objects) is allowed
                    continue

                line_no = 0
                for ln in lines:
                    line_no += 1
                    parts = ln.split()

                    # 1) column count
                    if len(parts) != 5:
                        problems.append(
                            f"{label_path} (line {line_no}): expected 5 values, got {len(parts)} -> '{ln}'"
                        )
                        continue

                    # 2) class id
                    try:
                        cid = int(parts[0])
                    except ValueError:
                        problems.append(
                            f"{label_path} (line {line_no}): class id is not int -> '{parts[0]}'"
                        )
                        continue

                    if cid not in self.class_names:
                        problems.append(
                            f"{label_path} (line {line_no}): class id {cid} not in {list(self.class_names.keys())}"
                        )
                        continue

                    # 3) coords
                    try:
                        x, y, w, h = map(float, parts[1:])
                    except ValueError:
                        problems.append(
                            f"{label_path} (line {line_no}): could not parse coords -> {parts[1:]}"
                        )
                        continue

                    if not (0.0 <= x <= 1.0 and 0.0 <= y <= 1.0 and 0.0 < w <= 1.0 and 0.0 < h <= 1.0):
                        problems.append(
                            f"{label_path} (line {line_no}): invalid coords x={x}, y={y}, w={w}, h={h}"
                        )

        if not problems:
            print("‚úÖ All labels validated successfully!")
        else:
            print(f"\n‚ö†Ô∏è Found {len(problems)} label issues:")
            for msg in problems[:50]:
                print("   -", msg)
            if len(problems) > 50:
                print(f"   ... and {len(problems) - 50} more")

        return problems
    
    def create_enhanced_data_yaml(self):
        """Create enhanced YOLO dataset configuration."""
        config = {
            'path': str(self.dataset_dir.absolute()),
            'train': 'images/train',
            'val': 'images/val',
            'nc': len(self.class_names),
            'names': self.class_names,
            # Enhanced configuration for traffic detection
            'download': None,
            'tid': None,
            'task': 'detect'
        }
        
        yaml_path = self.data_dir / "data.yaml"
        with open(yaml_path, 'w') as f:
            yaml.dump(config, f, default_flow_style=False)
        
        print(f"‚úì Enhanced data.yaml created")
        return yaml_path
    
    def train_optimized_model(self, model_size='s', epochs=120, batch=12,
                              device='auto', imgsz=800, workers=6):
        """Optimized training configuration for better accuracy."""
        import torch

        # Validate labels before training
        issues = self.validate_labels()
        if issues:
            print("\n‚ùå Label validation failed. Fix issues above before training.")
            raise SystemExit(1)

        # Create enhanced data.yaml
        data_yaml = self.create_enhanced_data_yaml()

        # Resolve device
        if device in ("", "auto", None):
            if torch.backends.mps.is_available():
                device = 'mps'
                print("‚öôÔ∏è Using Apple MPS (Metal) backend")
            elif torch.cuda.is_available():
                device = 'cuda'
                print("‚öôÔ∏è Using CUDA GPU")
            else:
                device = 'cpu'
                print("‚ö†Ô∏è No GPU detected, training on CPU (will be slow)")
        else:
            print(f"‚öôÔ∏è Using user-specified device: {device}")

        # Enhanced model sizes for better accuracy
        models = {
            's': 'yolov8s.pt',  # Small - better accuracy than nano
            'm': 'yolov8m.pt',  # Medium - good balance
            'l': 'yolov8l.pt',  # Large - high accuracy
        }

        if model_size not in models:
            print(f"‚ö†Ô∏è Model size '{model_size}' not available, using 's'")
            model_size = 's'

        print(f"\nüèãÔ∏è  Training Optimized YOLOv8{model_size.upper()}")
        print(f"   Enhanced Configuration:")
        print(f"   Epochs: {epochs} (optimized for convergence)")
        print(f"   Batch size: {batch} (memory-optimized)")
        print(f"   Image size: {imgsz} (higher resolution)")
        print(f"   Device: {device}")
        print(f"   Workers: {workers} (parallel loading)")
        print(f"   Model: {models[model_size]} (accuracy-focused)")

        # Load model
        model = YOLO(models[model_size])

        # Enhanced training arguments for better accuracy
        train_args = {
            'data': str(data_yaml),
            'epochs': epochs,
            'imgsz': imgsz,
            'batch': batch,
            'device': device,
            'workers': workers,
            'project': str(self.models_dir / "optimized"),
            'name': f'traffic_model_v2_{model_size}',
            'exist_ok': True,
            'resume': False,
            'pretrained': True,
            'patience': 50,  # Increased patience for convergence
            'save': True,
            'save_period': -1,
            'val': True,  # Enable validation for monitoring
            'plots': True,
            'verbose': True,
            'cache': False,
            
            # Enhanced optimizer settings
            'optimizer': 'AdamW',  # More stable than Adam
            'lr0': 0.005,  # Optimized learning rate
            'lrf': 0.01,
            'momentum': 0.95,
            'weight_decay': 0.0005,
            'warmup_epochs': 3.0,
            'warmup_momentum': 0.8,
            'warmup_bias_lr': 0.1,
            
            # Enhanced loss weights
            'box': 7.5,  # Box loss
            'cls': 0.5,  # Classification loss
            'dfl': 1.5,  # Distribution focal loss
            
            # Advanced augmentation (enabled)
            'hsv_h': 0.015,  # Hue augmentation
            'hsv_s': 0.7,    # Saturation augmentation
            'hsv_v': 0.4,    # Value augmentation
            'degrees': 5.0,   # Rotation augmentation
            'translate': 0.1, # Translation augmentation
            'scale': 0.5,     # Scale augmentation
            'shear': 0.0,     # Shear augmentation
            'perspective': 0.0, # Perspective augmentation
            'flipud': 0.0,    # Vertical flip
            'fliplr': 0.5,    # Horizontal flip
            'mosaic': 1.0,    # Mosaic augmentation
            'mixup': 0.15,    # MixUp augmentation
            'copy_paste': 0.0, # Copy-paste augmentation
            'auto_augment': 'randaugment', # Auto augment
            
            # Training stability
            'amp': True,  # Enable AMP for faster training
            'fraction': 1.0,
            'profile': False,
            'freeze': None,
            'multi_scale': True,  # Multi-scale training
            
            # Precision/Recall optimization
            'conf': 0.25,
            'iou': 0.7,
            'max_det': 300,
            'half': False,
            
            # Deterministic training for reproducibility
            'seed': 42,
            'deterministic': True,
        }
        
        print(f"\nüéØ Enhanced Training Configuration:")
        print(f"   Optimizer: {train_args['optimizer']}")
        print(f"   Learning Rate: {train_args['lr0']}")
        print(f"   Weight Decay: {train_args['weight_decay']}")
        print(f"   Multi-scale: {train_args['multi_scale']}")
        print(f"   Auto Augment: {train_args['auto_augment']}")
        print(f"   MixUp: {train_args['mixup']}")

        # Train with enhanced configuration
        results = model.train(**train_args)

        # Copy best model to main models folder with versioning
        best_model = self.models_dir / "optimized" / f"traffic_model_v2_{model_size}" / "weights" / "best.pt"
        if best_model.exists():
            final_model_path = self.models_dir / f"best_v2_{model_size}.pt"
            shutil.copy(best_model, final_model_path)
            print(f"\n‚úì Enhanced model saved to: {final_model_path}")
            
            # Also save as the default best model
            default_model_path = self.models_dir / "best.pt"
            shutil.copy(best_model, default_model_path)
            print(f"‚úì Default model updated: {default_model_path}")

        print(f"\nüéâ Enhanced training completed successfully!")
        
        return str(final_model_path)


def main():
    parser = argparse.ArgumentParser(
        description="Optimized Training Pipeline for Traffic Congestion Detection",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Enhanced Training Examples:
  # Complete optimized pipeline
  python train_optimized.py --all --model-size s --epochs 120 --imgsz 800
  
  # Extract enhanced frames
  python train_optimized.py --extract --fps 3 --max-frames 1000
  
  # Train with medium model (better accuracy)
  python train_optimized.py --train --model-size m --epochs 150 --batch 8
  
  # Train with large model (best accuracy, slower)
  python train_optimized.py --train --model-size l --epochs 100 --batch 4
  
  # GPU-optimized training
  python train_optimized.py --train --device cuda --batch 16 --workers 8
        """
    )
    
    # Actions
    parser.add_argument('--all', action='store_true',
                       help='Run complete optimized pipeline')
    parser.add_argument('--setup', action='store_true',
                       help='Setup directories only')
    parser.add_argument('--extract', action='store_true',
                       help='Extract enhanced frames')
    parser.add_argument('--check-labels', action='store_true',
                       help='Check labeling progress')
    parser.add_argument('--split', action='store_true',
                       help='Split dataset optimized')
    parser.add_argument('--train', action='store_true',
                       help='Train optimized model')
    
    # Enhanced extract options
    parser.add_argument('--fps', type=float, default=3,
                       help='Enhanced frames per second (default: 3)')
    parser.add_argument('--max-frames', type=int, default=1000,
                       help='Max frames per video (default: 1000)')
    
    # Enhanced training options
    parser.add_argument('--model-size', type=str, default='s',
                       choices=['s', 'm', 'l'],
                       help='Model size: s=small, m=medium, l=large (default: s)')
    parser.add_argument('--epochs', type=int, default=120,
                       help='Training epochs (default: 120)')
    parser.add_argument('--batch', type=int, default=12,
                       help='Batch size (default: 12)')
    parser.add_argument('--imgsz', type=int, default=800,
                       help='Image size (default: 800)')
    parser.add_argument('--device', type=str, default='auto',
                       help='Device: auto, mps, cuda, cpu (default: auto)')
    parser.add_argument('--workers', type=int, default=6,
                       help='Number of workers (default: 6)')
    
    args = parser.parse_args()
    
    # Initialize optimized pipeline
    pipeline = OptimizedTrainingPipeline()
    
    # Setup directories
    pipeline.setup_directories()
    
    # Execute requested actions
    if args.setup:
        print("\n‚úÖ Enhanced setup complete!")
        print(f"\nNext steps:")
        print(f"1. Add videos to: {pipeline.videos_dir}")
        print(f"2. Run: python train_optimized.py --extract")
        return
    
    if args.extract or args.all:
        count = pipeline.extract_frames(fps=args.fps, max_frames=args.max_frames)
        if count == 0:
            return
        
        if not args.all:
            print(f"\n‚úÖ Enhanced frames extracted!")
            print(f"\nNext steps:")
            print(f"1. Install labelImg: pip install labelImg")
            print(f"2. Label images: labelImg {pipeline.images_dir / 'train'} " +
                  f"{pipeline.labels_dir / 'train'}")
            print(f"3. After labeling, run: python train_optimized.py --split --train")
            return
    
    if args.check_labels or args.all:
        has_labels = pipeline.check_labeling_status()
        if not has_labels and not args.all:
            return
    
    if args.split or args.all:
        pipeline.split_dataset()
        
        if not args.all and not args.train:
            print(f"\n‚úÖ Dataset split!")
            print(f"\nNext steps:")
            print(f"Run: python train_optimized.py --train")
            return
    
    if args.train or args.all:
        model_path = pipeline.train_optimized_model(
            model_size=args.model_size,
            epochs=args.epochs,
            batch=args.batch,
            device=args.device,
            imgsz=args.imgsz,
            workers=args.workers
        )
        
        print(f"\nüéâ Optimized training complete!")
        print(f"\nEnhanced model saved to: {model_path}")
        print(f"\nNext steps:")
        print(f"Test your enhanced model:")
        print(f"python detect.py --input video.mp4 --model {model_path}")
        
        print(f"\nüìä Model comparison:")
        print(f"Previous model: YOLOv8n (nano) - 67.4% mAP50")
        print(f"Enhanced model: YOLOv8{args.model_size.upper()} - Expected ~75-85% mAP50")
    
    if not any([args.all, args.setup, args.extract, args.check_labels, 
                args.split, args.train]):
        parser.print_help()


if __name__ == "__main__":
    main()